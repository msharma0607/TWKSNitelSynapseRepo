{
	"name": "NitelDataPOC_Latest",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "twksnitelspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "de015648-3bd0-4e99-b598-653f4f9d8370"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/24bf2188-543d-4bd6-a859-4ce11f290d4e/resourceGroups/twks_rg/providers/Microsoft.Synapse/workspaces/twksnitelsynapse/bigDataPools/twksnitelspark",
				"name": "twksnitelspark",
				"type": "Spark",
				"endpoint": "https://twksnitelsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/twksnitelspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Required Imports"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.types import *\n",
					"from pyspark.sql.functions import *"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Registering Schema"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"network_event_schema = StructType()\\\n",
					".add(\"status\", StringType())\\\n",
					".add(\"code\", StringType())\\\n",
					".add(\"result\", StructType().add(\"totalCount\",StringType())\\\n",
					"                                    .add(\"count\", StringType())\\\n",
					"                                    .add(\"entry\", ArrayType(\\\n",
					"                                        StructType().add(\"name\", StringType())\\\n",
					"                                                    .add(\"uuid\", StringType())\\\n",
					"                                                    .add(\"source\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"destination\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"sourceUser\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"category\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"application\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"service\", StructType().add(\"member\", ArrayType(StringType())))\\\n",
					"                                                    .add(\"action\", StringType())\n",
					"\n",
					"                                                    \n",
					"                                    )))\n",
					""
				],
				"execution_count": 116
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Event Hubs Configuratin Init"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\n",
					"eventHubname= \"twks-nitel-eventhub\"\n",
					"#connectionString = \"Endpoint=sb://twks-nitel-eventhub-ns.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=ZoiVkf7QQAokyDknOwm8znLFFN0Qz0IzX+AEhBrvSxk=\"\n",
					"connectionString = \"Endpoint=sb://twks-nitel-eventhub-ns.servicebus.windows.net/;SharedAccessKeyName=EventReaderPolicy;SharedAccessKey=AwJWaejO1DdHY2OqM9HLdWrGTTbXmzxaZ+AEhJ2FQnI=\"\n",
					"\n",
					"eventHubConnectionStringWithEntity = connectionString + \";EntityPath=\" + eventHubname\n",
					"\n",
					"\n",
					"startingEventPosition = {\n",
					"  \"offset\": \"@latest\",  \n",
					"  \"seqNo\": -1,            #not in use\n",
					"  \"enqueuedTime\": None,   #not in use\n",
					"  \"isInclusive\": True\n",
					"}\n",
					"\n",
					"ehConf = {}\n",
					"ehConf['eventhubs.connectionString'] = sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(eventHubConnectionStringWithEntity)\n",
					"\n",
					"ehConf[\"eventhubs.startingPosition\"] = json.dumps(startingEventPosition)\n",
					"ehConf[\"eventhubs.consumerGroup\"] = 'twks-nitel-consumer-group'\n",
					"\n",
					"root_path = \"abfss://twks-nitel-datalake@twksnitelstorageacc.dfs.core.windows.net/\"\n",
					"parquet_data_path = root_path + \"/datacaptor-bronze-parquet\"\n",
					"delta_data_path = root_path + \"/datacaptor-bronze-delta\"\n",
					"json_data_path = root_path + \"/datacaptor-bronze-json\"\n",
					"checkpoint_loc = root_path + \"/checkpoint-dir\"\n",
					""
				],
				"execution_count": 36
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Reading Event Hub Data from Spark Streaming"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"edf = spark.readStream.format(\"eventhubs\").options(**ehConf).load()\n",
					"\n",
					"nitel_raw_df = edf.withColumn(\"nitel_raw_data\", col(\"body\").cast(\"string\")).select('properties','nitel_raw_data')\n",
					"\n",
					"nitel_captor_data_df = nitel_raw_df.select(\"properties\",from_json(\"nitel_raw_data\", network_event_schema).alias(\"nitel_captor_data\")).select(\"properties\",\"nitel_captor_data.status\",\"nitel_captor_data.code\",\"nitel_captor_data.result.*\")\n",
					"\n",
					"explode_df = nitel_captor_data_df.select('properties','status','code','totalCount', 'count', explode(\"entry\").alias(\"entry\")).select(element_at('properties','id').alias(\"id\"),element_at('properties','timestamp').alias(\"timestamp\"),'status','code','totalCount','count','entry.*')\n",
					"\n",
					"explode_df.printSchema\n",
					""
				],
				"execution_count": 89
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"anomaly_streaming_df = explode_df.filter(array_contains(\"source.member\",\"any\"))\\\n",
					"             .filter(\"status is not null\")\\\n",
					"             .filter(array_contains(\"destination.member\",\"any\"))\\\n",
					"             .filter(array_contains(\"sourceUser.member\",\"any\"))\\\n",
					"             .filter(array_contains(\"category.member\",\"any\"))\\\n",
					"             .filter(array_contains(\"application.member\",\"any\"))\\\n",
					"             .filter(array_contains(\"service.member\",\"any\"))\\\n",
					"             .filter(\"action=='allow'\")\\\n",
					"             .filter(\"id is not null\")\n",
					"             select('id','timestamp','name','uuid','action')\\\n",
					".withColumnRenamed(\"id\",\"EventId\")\\\n",
					".withColumnRenamed(\"timestamp\",\"EventTimestamp\")\\\n",
					".withColumnRenamed(\"name\",\"ConfigurationName\")\\\n",
					".withColumnRenamed(\"uuid\",\"ConfigUUID\")\\\n",
					".withColumnRenamed(\"action\",\"ConfigAction\")\\\n",
					".withColumn(\"IsAnomaly\", lit(\"true\"))\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"    anomalyStreamingQuery = anomaly_streaming_df.writeStream.format(\"memory\").queryName(\"AnomaliesTable\").trigger(processingTime=\"10 seconds\").start()"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Data without Anomalies"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"non_anomaly_df = full_df.join(anomaly_df,[full_df[\"Id\"]==anomaly_df[\"EventId\"],full_df[\"uuid\"]==anomaly_df[\"ConfigUUID\"]],\"anti\")\n",
					"non_anomaly_df = non_anomaly_df\\\n",
					".select('id','timestamp','name','uuid','action')\\\n",
					".withColumnRenamed(\"id\",\"EventId\")\\\n",
					".withColumnRenamed(\"timestamp\",\"EventTimestamp\")\\\n",
					".withColumnRenamed(\"name\",\"ConfigurationName\")\\\n",
					".withColumnRenamed(\"uuid\",\"ConfigUUID\")\\\n",
					".withColumnRenamed(\"action\",\"ConfigAction\")\\\n",
					".withColumn(\"IsAnomaly\", lit(\"false\"))"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\n",
					"import com.microsoft.spark.sqlanalytics\n",
					"from com.microsoft.spark.sqlanalytics.Constants import Constants\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\n",
					"\n",
					"anomaly_df.write\\\n",
					".option(Constants.SERVER, \"twksnitelsynapse.sql.azuresynapse.net\")\\\n",
					".option(Constants.TEMP_FOLDER, \"abfss://twks-nitel-datalake@twksnitelstorageacc.dfs.core.windows.net/synapsesql\")\\\n",
					" .mode(\"append\")\\\n",
					" .synapsesql( \"twksniteldedeicatedsqlpool.niteldb.NitelFirewallData\", \\\n",
					"                Constants.INTERNAL, \\\n",
					"                None)"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\n",
					"\n",
					"non_anomaly_df.write\\\n",
					".option(Constants.SERVER, \"twksnitelsynapse.sql.azuresynapse.net\")\\\n",
					".option(Constants.TEMP_FOLDER, \"abfss://twks-nitel-datalake@twksnitelstorageacc.dfs.core.windows.net/synapsesql\")\\\n",
					" .mode(\"append\")\\\n",
					" .synapsesql( \"twksniteldedeicatedsqlpool.niteldb.NitelFirewallData\", \\\n",
					"                Constants.INTERNAL, \\\n",
					"                None)"
				]
			}
		]
	}
}